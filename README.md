# Endurance
Simple implementation of automatic differentiation reverse mode. 

Note: The implementation is only for educational purposes. The code could be optimized and make it more flexible.
I intentionally wrote the operations explicitely so i could think about what happens.
I just wanted to try to implement backpropagation after i studied it from: 1) https://cs231n.github.io/optimization-2/  
2) https://arxiv.org/abs/1502.05767 .


Other resource that i have consulted to compare my code:    
https://sidsite.com/posts/autodiff/   
https://github.com/karpathy/micrograd
